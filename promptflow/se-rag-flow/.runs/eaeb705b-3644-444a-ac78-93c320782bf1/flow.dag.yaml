inputs:
  question:
    type: string
    default: How to use SDK V2?
    is_chat_input: false
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
    evaluation_only: false
    is_chat_output: false
nodes:
- name: lookup
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.common_index_lookup.search
  inputs:
    mlindex_content: "embeddings:\n  api_base: https://saschac-openai.openai.azure.com/\n  api_type: azure\n  api_version: 2023-07-01-preview\n  batch_size: '1'\n  connection:\n    id: /subscriptions/0b962213-fc84-4c8d-bc1a-2dce59741c5a/resourceGroups/saschac-openai/providers/Microsoft.MachineLearningServices/workspaces/saschac-azureml/connections/azure-open-ai\n  connection_type: workspace_connection\n  deployment: text-embedding-ada-002\n  dimension: 1536\n  kind: open_ai\n  model: text-embedding-ada-002\n  schema_version: '2'\nindex:\n  api_version: 2023-07-01-Preview\n  connection:\n    id: /subscriptions/0b962213-fc84-4c8d-bc1a-2dce59741c5a/resourceGroups/saschac-openai/providers/Microsoft.MachineLearningServices/workspaces/saschac-azureml/connections/saschac-aisearch-std\n  connection_type: workspace_connection\n  endpoint: https://saschac-aisearch-std.search.windows.net\n  engine: azure-sdk\n  field_mapping:\n    content: content\n    embedding: content_vector\n    metadata: metadata\n  index: index_se_kb\n  kind: acs\n  semantic_configuration_name: my-semantic-config\n"
    queries: "${inputs.question}"
    query_type: "Semantic"
    top_k: 2
  aggregation: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: "${lookup.output}"
  aggregation: false
- name: answer_the_question_with_context
  type: llm
  source:
    type: code
    path: answer_the_question_with_context.jinja2
  inputs:
    deployment_name: "gpt-35-turbo-16k"
    temperature: 0
    top_p: 1
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    suffix: ""
    echo: false
    best_of: 1
    prompt_text: "${Prompt_variants.output}"
  api: chat
  provider: AzureOpenAI
  connection: azure-open-ai
  module: promptflow.tools.aoai
  aggregation: false
- name: Prompt_variants
  type: prompt
  source:
    type: code
    path: Prompt_variants.jinja2
  inputs:
    contexts: "${generate_prompt_context.output}"
    question: "${inputs.question}"
  aggregation: false
environment:
  python_requirements_txt: requirements.txt
